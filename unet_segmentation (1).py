# -*- coding: utf-8 -*-
"""Unet_Segmentation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NYGuXcVTLmjyRFuxhkemfLtuynNw5h1C
"""

from google.colab import drive
drive.mount('/content/drive')

import os

BASE_PATH = "/content/drive/MyDrive/img"

TRAIN_IMG  = os.path.join(BASE_PATH, "train")
TRAIN_MASK = os.path.join(BASE_PATH, "train_labels")

VAL_IMG  = os.path.join(BASE_PATH, "val")
VAL_MASK = os.path.join(BASE_PATH, "val_labels")

print("Train images:", len(os.listdir(TRAIN_IMG)))
print("Train masks :", len(os.listdir(TRAIN_MASK)))
print("Val images  :", len(os.listdir(VAL_IMG)))
print("Val masks   :", len(os.listdir(VAL_MASK)))

train_imgs  = set(os.listdir(TRAIN_IMG))
train_masks = set(os.listdir(TRAIN_MASK))

print("Images without masks:", train_imgs - train_masks)
print("Masks without images:", train_masks - train_imgs)

!pip install segmentation-models-pytorch albumentations

import cv2
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import segmentation_models_pytorch as smp
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap

class SegDataset(Dataset):
    def __init__(self, img_dir, mask_dir, img_size=256):
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.img_size = img_size
        self.images = sorted(os.listdir(img_dir))

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = self.images[idx]

        # ---- IMAGE ----
        img = cv2.imread(os.path.join(self.img_dir, img_name))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (self.img_size, self.img_size))
        img = img / 255.0
        img = torch.tensor(img).permute(2, 0, 1).float()

        # ---- MASK ----
        mask = cv2.imread(os.path.join(self.mask_dir, img_name))
        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)
        mask = cv2.resize(mask, (self.img_size, self.img_size))

        label = np.zeros(mask.shape[:2], dtype=np.uint8)
        label[mask[:, :, 0] > 200] = 1   # ruins
        label[mask[:, :, 1] > 200] = 2   # vegetation

        label = torch.tensor(label).long()

        return img, label

train_ds = SegDataset(TRAIN_IMG, TRAIN_MASK)
val_ds   = SegDataset(VAL_IMG, VAL_MASK)

train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)
val_loader   = DataLoader(val_ds, batch_size=2, shuffle=False, num_workers=2)

device = "cuda" if torch.cuda.is_available() else "cpu"

model = smp.Unet(
    encoder_name="resnet34",
    encoder_weights="imagenet",
    in_channels=3,
    classes=3
).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

!pip install -q tqdm

from tqdm import tqdm

EPOCHS = 10

for epoch in range(EPOCHS):
    model.train()
    running_loss = 0

    progress = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")

    for imgs, masks in progress:
        imgs = imgs.to(device, non_blocking=True)
        masks = masks.to(device, non_blocking=True)

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        progress.set_postfix(loss=loss.item())

    print(f"âœ… Epoch {epoch+1}/{EPOCHS} completed | Avg Loss: {running_loss/len(train_loader):.4f}")

MODEL_PATH = "/content/drive/MyDrive/unet_archaeology.pth"
torch.save(model.state_dict(), MODEL_PATH)
print("Model saved to Drive")

pred_cmap = ListedColormap(["#d3d3d3", "red", "green"])

model.eval()
img_name = np.random.choice(os.listdir(VAL_IMG))

img = cv2.imread(os.path.join(VAL_IMG, img_name))
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img = cv2.resize(img, (512, 512))
img_tensor = torch.tensor(img / 255.0).permute(2, 0, 1).float().unsqueeze(0).to(device)

with torch.no_grad():
    pred = model(img_tensor)
    pred_mask = torch.argmax(pred, dim=1).squeeze().cpu().numpy()

plt.figure(figsize=(15,5))

plt.subplot(1,2,1)
plt.title("Input Image")
plt.imshow(img)
plt.axis("off")

plt.subplot(1,2,2)
plt.title("Predicted Mask")
plt.imshow(pred_mask, cmap=pred_cmap, vmin=0, vmax=2)
plt.axis("off")

plt.show()